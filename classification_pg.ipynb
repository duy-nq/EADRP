{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import accuracy_score\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, train_test_split, KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'car_name': 'ev_golf',\n",
    "    'seed': 23,\n",
    "    'num_folds': 5,\n",
    "    'dataset': '',\n",
    "    'threshold': 30\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = './dataset/{name}.csv'.format(name=config.car_name)\n",
    "OUT_PATH = './model/{name}'.format(name=config.car_name)\n",
    "SEED = config.seed\n",
    "NUM_FOLDS = config.num_folds\n",
    "MODEL_LIST = [\n",
    "    'Logistic Regression',\n",
    "    'SVC',\n",
    "    'Random Forest C',\n",
    "    'AdaBoost C'\n",
    "]\n",
    "\n",
    "LR_PARAMS = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', None],\n",
    "    'multi_class': ['ovr', 'multinomial'],\n",
    "    'C': np.linspace(0.001, 5, 2),\n",
    "    'l1_ratio': np.linspace(0, 1, 2)\n",
    "}\n",
    "\n",
    "SVM_PARAMS = {\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'C': np.linspace(0.001, 1, 2),\n",
    "    'gamma': np.linspace(0.001, 1, 2)\n",
    "}\n",
    "\n",
    "RF_PARAMS = {\n",
    "    'max_features':[2,3],\n",
    "    'min_samples_leaf':[2]\n",
    "}\n",
    "\n",
    "AB_PARAMS = {\n",
    "    'learning_rate': np.linspace(0.001, 0.8, 2),\n",
    "    'n_estimators': [50]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data():\n",
    "    df = pd.read_csv(FILE_PATH)\n",
    "    col = ['consumption(kWh/100km)','manufacturer','model','version','fuel_date','fuel_type','power(kW)']\n",
    "    for i in col:\n",
    "        if i in df.columns:\n",
    "            df = df.drop(i,axis=1)\n",
    "    df['encoded_driving_style']  = df['encoded_driving_style'].astype('int')\n",
    "    df['park_heating']  = df['park_heating'].astype('int')\n",
    "\n",
    "    df['ecr_dev_type'] = df['ecr_deviation'].apply(lambda x: 1 if x >= 0 else 0 )\n",
    "    df.drop('ecr_deviation',axis=1,inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting Data (80/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df: pd.DataFrame):\n",
    "    def scaler_x(data):\n",
    "        scaler = MinMaxScaler()\n",
    "        return scaler.fit_transform(data)\n",
    "    \n",
    "    def scaler_y(data):\n",
    "        scaler = MinMaxScaler()\n",
    "        return scaler.fit_transform(data.reshape(-1, 1))\n",
    "    \n",
    "    train, test  = train_test_split(df, test_size = 0.2, random_state = SEED)\n",
    "\n",
    "    y_train = train['ecr_dev_type']\n",
    "    X_train = train.drop('ecr_dev_type',axis=1)\n",
    "\n",
    "    y_test = test['ecr_dev_type']\n",
    "    X_test = test.drop('ecr_dev_type',axis=1)\n",
    "\n",
    "    y_train = y_train.values\n",
    "    y_test = y_test.values\n",
    "\n",
    "    return scaler_x(X_train), scaler_y(y_train), scaler_x(X_test), scaler_y(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_train(models, X_train, y_train, is_plot: bool):\n",
    "    def plot():\n",
    "        train_score = pd.DataFrame(data = training_score, columns = ['Training_Accuracy'])\n",
    "        train_score.index = ['LR',  'SVM',  'RF', 'AB']\n",
    "        train_score = train_score.sort_values(by = 'Training_Accuracy')\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        sns.barplot(x=train_score.index, y='Training_Accuracy', data=train_score,palette=\"rocket\")\n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel('Training_Accuracy')\n",
    "        plt.title('Training_Accuracy vs Models')\n",
    "    \n",
    "    training_score = []\n",
    "    for model in models:\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred_train = model.predict(X_train)\n",
    "        train_mse = accuracy_score(y_train, y_pred_train)\n",
    "        training_score.append(train_mse)\n",
    "    \n",
    "    if is_plot:\n",
    "        plot()\n",
    "\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_train(models, X_train, y_train, is_plot: bool):\n",
    "    def cross_validation(model, X_train, y_train):\n",
    "        kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "        \n",
    "        neg_x_val_score = cross_val_score(model, X_train, y_train, cv = kf, n_jobs = -1, scoring = 'accuracy')\n",
    "        x_val_score = np.round(neg_x_val_score, 5)\n",
    "\n",
    "        return x_val_score.mean()\n",
    "    \n",
    "    def plot():\n",
    "        x_val_score = pd.DataFrame(data = cv_score, columns = ['Cross Validation Scores (Accuracy)'])\n",
    "        x_val_score.index = ['Logistic Reg',  'SVM',  'Random Forest', 'Ada Boost']\n",
    "        x_val_score = x_val_score.round(5)\n",
    "        x_val_score  = x_val_score.sort_values(by = 'Cross Validation Scores (Accuracy)')\n",
    "\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        sns.barplot(x=x_val_score.index, y='Cross Validation Scores (Accuracy)', data=x_val_score,palette=\"rocket\")\n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Cross Validation Scores (Accuracy) vs models')\n",
    "        plt.show()\n",
    "\n",
    "    cv_score = []\n",
    "    for model in models:\n",
    "        cv_score.append(cross_validation(model, X_train, y_train))\n",
    "\n",
    "    if is_plot:\n",
    "        plot()\n",
    "\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gs_train(models, X_train, y_train, is_plot: bool):\n",
    "    def grid_search_cv(model, params):\n",
    "        kfold = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "        global best_params, best_score\n",
    "\n",
    "        grid_search = RandomizedSearchCV(\n",
    "            estimator = model, \n",
    "            param_distributions=params,\n",
    "            verbose=1,\n",
    "            n_iter=5, \n",
    "            random_state=SEED,\n",
    "            cv=kfold, \n",
    "            scoring='accuracy',\n",
    "            n_jobs = -1\n",
    "        )\n",
    "\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_params = grid_search.best_params_\n",
    "        best_score = (np.round(grid_search.best_score_, 5))\n",
    "        \n",
    "        return best_params, best_score\n",
    "\n",
    "    def repr(name, value_1, value_2):\n",
    "        return '{} best params: {} and best score: {:0.5f}'.format(name, value_1, value_2)\n",
    "\n",
    "    def plot():\n",
    "        optimized_scores = pd.DataFrame({'Optimized Scores':[lr_best_score, svm_best_score, rf_best_score,ab_best_score] })\n",
    "        optimized_scores.index = ['Logistic Reg',  'SVM',  'Random Forest', 'Ada Boost']\n",
    "        optimized_scores = optimized_scores.sort_values(by = 'Optimized Scores')\n",
    "        optimized_scores\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        sns.barplot(x=optimized_scores.index, y='Optimized Scores', data=optimized_scores,palette=\"rocket\")\n",
    "        plt.xlabel('Models')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.title('Optimized_Accuracy vs models')\n",
    "        plt.show()\n",
    "\n",
    "    lr_best_params, lr_best_score = grid_search_cv(models[0], LR_PARAMS)\n",
    "    svm_best_params, svm_best_score = grid_search_cv(models[1], SVM_PARAMS)\n",
    "    rf_best_params, rf_best_score = grid_search_cv(models[2], RF_PARAMS)\n",
    "    ab_best_params, ab_best_score = grid_search_cv(models[3], AB_PARAMS)\n",
    "\n",
    "    if is_plot:\n",
    "        plot()\n",
    "\n",
    "    opt_model = [\n",
    "        LogisticRegression(**lr_best_params),\n",
    "        SVC(**svm_best_params),\n",
    "        RandomForestClassifier(**rf_best_params),\n",
    "        AdaBoostClassifier(**ab_best_params)\n",
    "    ]\n",
    "\n",
    "    return opt_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, X_test, y_test):\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    return accuracy_score(y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FINAL PLOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_plot(mse_values):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(MODEL_LIST, mse_values, color='skyblue')\n",
    "    plt.xlabel('Models')\n",
    "    plt.ylabel('Mean Squared Error (MSE)')\n",
    "    plt.title('Mean Squared Error Comparison of Models')\n",
    "    plt.xticks(rotation=45)  \n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model_name, model):\n",
    "    with open('./model/{}.pkl'.format(model_name), 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN IT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = process_data()\n",
    "X_train, y_train, X_test, y_test = split_data(data)\n",
    "\n",
    "lr = LogisticRegression(n_jobs = -1)\n",
    "svm = SVC(random_state = SEED)\n",
    "rf =  RandomForestClassifier(n_jobs = -1, random_state = SEED)\n",
    "ab = AdaBoostClassifier(random_state = SEED)\n",
    "\n",
    "models = [lr, svm, rf, ab]\n",
    "\n",
    "init_models = basic_train(models, X_train, y_train, is_plot=False)\n",
    "ft_models = gs_train(init_models, X_train, y_train, is_plot=False)      \n",
    "\n",
    "# 0 is Linear Regression\n",
    "# 1 is Support Vector Classifier\n",
    "# 2 is Random Forest Classifier\n",
    "# 3 is AdaBoost Classifier\n",
    "final_result = []\n",
    "for model in ft_models:\n",
    "    final_result.append(test(model, X_test, y_test))\n",
    "\n",
    "save_model('ev_golf', models[0])\n",
    "save_model('mitsubishi', models[1])\n",
    "save_model('renault', models[2])\n",
    "save_model('tesla', models[3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
